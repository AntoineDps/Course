{"cells":[{"cell_type":"markdown","metadata":{"id":"9cA_kcvoB3-O"},"source":["**Exercise 6.4**\n","\n","MNIST with fully connected networks and grid/random search"]},{"cell_type":"code","execution_count":91,"metadata":{"executionInfo":{"elapsed":748,"status":"ok","timestamp":1665174030375,"user":{"displayName":"Antoine Dupuis","userId":"12168416720763859895"},"user_tz":-120},"id":"2UyhnBFQomM8"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import tensorflow as tf\n","from tabulate import tabulate\n","from tensorflow.keras import layers"]},{"cell_type":"markdown","metadata":{"id":"Se2-q7KoddJ0"},"source":["The MNIST data base of handwritten numbers is directly available through KERAS. The following codeblocks download and preprocess the data. "]},{"cell_type":"code","execution_count":92,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665174031153,"user":{"displayName":"Antoine Dupuis","userId":"12168416720763859895"},"user_tz":-120},"id":"bhMqBcW9pIGl"},"outputs":[],"source":["(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data() # download test and train data\n","\n","\n","\n","# split test data into validation and test data\n","x_valid = x_test[8000:] \n","y_valid = y_test[8000:]\n","x_test = x_test[:8000]\n","y_test = y_test[:8000]\n","\n","# Hint: convert integer RGB values (0-255) to float values (0-1)\n"]},{"cell_type":"code","execution_count":93,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1665174031153,"user":{"displayName":"Antoine Dupuis","userId":"12168416720763859895"},"user_tz":-120},"id":"CtfKNKw2pohq","outputId":"815d47fb-5d57-46e0-f860-bc39f35b9d10"},"outputs":[{"output_type":"stream","name":"stdout","text":["x_train shape: (60000, 28, 28)\n","60000 train samples\n","2000 validation samples\n","8000 test samples\n"]}],"source":["# shows shapes and train, validation and test dataset size\n","print(\"x_train shape:\", x_train.shape)\n","print(x_train.shape[0], \"train samples\")\n","print(x_valid.shape[0], \"validation samples\")\n","print(x_test.shape[0], \"test samples\")\n"]},{"cell_type":"markdown","metadata":{"id":"7QNQLm-Vdrj4"},"source":["In this exercise, a fully connected neural network is used to predict the handwritten numbers. To do this, we reformat the pictures with 28x28 pixels into a vector with a length of 28x28=784."]},{"cell_type":"markdown","metadata":{"id":"SOB0OIsBm5O5"},"source":["# Normalization\n","\n","Here we also normalise the input data by simply dividing by / 255"]},{"cell_type":"code","execution_count":94,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665174031153,"user":{"displayName":"Antoine Dupuis","userId":"12168416720763859895"},"user_tz":-120},"id":"MjiaSxfZqSTF","outputId":"4fd04c5d-c54a-43d4-f4df-4e0d09e55125"},"outputs":[{"output_type":"stream","name":"stdout","text":["x_train shape: (60000, 784)\n"]}],"source":["# reshape the image matrices to vectors\n","x_train = x_train.reshape(-1, 28**2).astype(\"float32\") / 255.0\n","x_valid = x_valid.reshape(-1, 28**2).astype(\"float32\") / 255.0\n","x_test = x_test.reshape(-1, 28**2).astype(\"float32\") / 255.0\n","# print new shape\n","print(\"x_train shape:\", x_train.shape)"]},{"cell_type":"markdown","metadata":{"id":"Ceq-buDaeDzK"},"source":["We use \"onehot\" encoding of the classes. This means a \"zero\" is encoded as `[1,0,0,0,0,0,0,0,0,0]` and a \"one\" as `[0,1,0,0,0,0,0,0,0,0]` etc. \n","This is done because our network will have ten output nodes with the output node with the largest value being the predicted number."]},{"cell_type":"code","execution_count":95,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1665174032194,"user":{"displayName":"Antoine Dupuis","userId":"12168416720763859895"},"user_tz":-120},"id":"JrY-diyvpw3b"},"outputs":[],"source":["# convert class vectors to binary class matrices (10 numbers/classes)\n","y_train_onehot = tf.keras.utils.to_categorical(y_train, 10)\n","y_valid_onehot = tf.keras.utils.to_categorical(y_valid, 10)\n","y_test_onehot = tf.keras.utils.to_categorical(y_test, 10)\n","\n","#print(y_test_onehot[0])"]},{"cell_type":"code","execution_count":96,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1665174032195,"user":{"displayName":"Antoine Dupuis","userId":"12168416720763859895"},"user_tz":-120},"id":"BCx9E6TKSqZS","outputId":"37094990-bc39-48c0-ef36-9f54a35eba1f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_34\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_193 (Dense)           (None, 10)                7850      \n","                                                                 \n"," dense_194 (Dense)           (None, 10)                110       \n","                                                                 \n","=================================================================\n","Total params: 7,960\n","Trainable params: 7,960\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}],"source":["# define model here\n","\n","nb_nodes = 10\n","nb_layers = 1\n","\n","model = tf.keras.models.Sequential()\n","model.add(layers.Dense(nb_nodes, activation = 'ReLU', input_shape=(784,)))\n","\n","for i in range (1,nb_layers):\n","  model.add(layers.Dense(nb_nodes, activation = 'ReLU'))\n","    \n","\n","model.add(layers.Dense(10, activation = 'softmax'))  # softmax actication to transform output into probabiliites\n","\n","print(model.summary())"]},{"cell_type":"code","execution_count":97,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":141875,"status":"ok","timestamp":1665174174066,"user":{"displayName":"Antoine Dupuis","userId":"12168416720763859895"},"user_tz":-120},"id":"cHOs__1bsUFw","outputId":"ccbb4a11-6e89-4cde-ac4d-492452517aab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1875/1875 [==============================] - 12s 6ms/step - loss: 0.4848 - accuracy: 0.8626 - val_loss: 0.2133 - val_accuracy: 0.9400 - train_loss: 0.3023 - train_acc: 0.9146\n","Epoch 2/10\n","1875/1875 [==============================] - 15s 8ms/step - loss: 0.2852 - accuracy: 0.9184 - val_loss: 0.1842 - val_accuracy: 0.9455 - train_loss: 0.2599 - train_acc: 0.9270\n","Epoch 3/10\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.2591 - accuracy: 0.9260 - val_loss: 0.1732 - val_accuracy: 0.9515 - train_loss: 0.2438 - train_acc: 0.9310\n","Epoch 4/10\n","1875/1875 [==============================] - 10s 5ms/step - loss: 0.2430 - accuracy: 0.9314 - val_loss: 0.1626 - val_accuracy: 0.9500 - train_loss: 0.2272 - train_acc: 0.9363\n","Epoch 5/10\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.2318 - accuracy: 0.9346 - val_loss: 0.1618 - val_accuracy: 0.9540 - train_loss: 0.2199 - train_acc: 0.9377\n","Epoch 6/10\n","1875/1875 [==============================] - 10s 5ms/step - loss: 0.2226 - accuracy: 0.9372 - val_loss: 0.1557 - val_accuracy: 0.9545 - train_loss: 0.2129 - train_acc: 0.9394\n","Epoch 7/10\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.2146 - accuracy: 0.9388 - val_loss: 0.1590 - val_accuracy: 0.9530 - train_loss: 0.2047 - train_acc: 0.9423\n","Epoch 8/10\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.2070 - accuracy: 0.9408 - val_loss: 0.1576 - val_accuracy: 0.9515 - train_loss: 0.1968 - train_acc: 0.9435\n","Epoch 9/10\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.2016 - accuracy: 0.9430 - val_loss: 0.1641 - val_accuracy: 0.9505 - train_loss: 0.1960 - train_acc: 0.9419\n","Epoch 10/10\n","1875/1875 [==============================] - 10s 5ms/step - loss: 0.1969 - accuracy: 0.9438 - val_loss: 0.1560 - val_accuracy: 0.9545 - train_loss: 0.1846 - train_acc: 0.9469\n"]}],"source":["# create the model with specifying loss, optimizer and metric\n","model.compile(\n","    loss='categorical_crossentropy',  # the recommended loss for a classification task is 'categorical_crossentropy' (see lecture for details)\n","    optimizer= 'adam',\n","    metrics=['accuracy']) # we use accuracy to quanitfy to network performance. \n","\n","# define callbacks for training\n","save_best = tf.keras.callbacks.ModelCheckpoint( # to save model and model weights at some frequency\n","    \"best_model_{}.h5\".format(model.name),\n","    save_best_only=True, # only save the best last model\n","    monitor=\"val_accuracy\", # what conditionned the saving\n","    save_weights_only=True, # only weight are saved\n",")\n","\n","# Keras calculates training accuracy and loss during the training and with regularization applied,\n","# while the validation metrics are calculated at the end of each epoch.\n","# This callback calculates the training metrics the same way as for the validation\n","class CalculateMetrics(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}): # at the end of each epoch\n","        train_loss, train_acc = model.evaluate(x_train, y_train_onehot, verbose=0) # get training metrics\n","        logs[\"train_loss\"] = train_loss # display train_loss\n","        logs[\"train_acc\"] = train_acc # display train_acc\n","\n","results = model.fit(\n","    x_train, y_train_onehot,\n","    validation_data=(x_valid, y_valid_onehot), # display validation metric and loss\n","    \n","    batch_size=32,\n","    epochs=10,\n","    callbacks=[ # 3 callbacks !\n","        save_best, # defined above \n","        CalculateMetrics(), # defined above\n","        tf.keras.callbacks.CSVLogger(\"history_{}.csv\".format(model.name)) # defined now ! # write epcohs result to a CSV file\n","    ]\n","    )\n","\n","# the \"dynamic\" loss calculation is automaticaly (by KERAS) displayed in the console"]},{"cell_type":"code","execution_count":98,"metadata":{"id":"CSpacCi6uauS","colab":{"base_uri":"https://localhost:8080/","height":296},"executionInfo":{"status":"ok","timestamp":1665174174067,"user_tz":-120,"elapsed":11,"user":{"displayName":"Antoine Dupuis","userId":"12168416720763859895"}},"outputId":"afcc6af4-6518-4e2b-bf36-efffbee34e4d"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["final accuracy on the test data set : 0.9269999861717224\n"]}],"source":["# load best model\n","model.load_weights(f\"best_model_{model.name}.h5\")\n","\n","# ------------------------\n","# ---     Plotting     ---\n","# ------------------------\n","\n","# plot training history\n","history = np.genfromtxt(f\"history_{model.name}.csv\", delimiter=\",\", names=True)\n","\n","# add plots below - Plot the training and validation accuracy as a function of epoch\n","train_acc = history[\"train_acc\"][1:]\n","val_accuracy = history[\"val_accuracy\"][1:]\n","\n","plt.plot(train_acc,label=\"train accuracy\")\n","plt.plot(val_accuracy,label=\"validation accuracy\")\n","plt.legend()\n","plt.xlabel(\"Epoch-1\")\n","plt.ylabel(\"accuracy\")\n","plt.show()\n","\n","# final accuracy on the test data set\n","print(\"final accuracy on the test data set :\", model.evaluate(x_test, y_test_onehot, verbose=0, batch_size=128)[1])"]},{"cell_type":"markdown","metadata":{"id":"ZaLRaRuv3L2Z"},"source":["Above, the training and validation accuracy as a function of epoch is plotted. In addition, the final accuracy on the test dataset is given."]},{"cell_type":"code","execution_count":99,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3036,"status":"ok","timestamp":1665174177638,"user":{"displayName":"Antoine Dupuis","userId":"12168416720763859895"},"user_tz":-120},"id":"jErly75Vua2S","outputId":"4d2fd30f-adff-498a-b0fd-ad7882ca80f3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model performance :\n","|            |     Loss |   Accuracy |   Test error rate [%] |\n","|------------+----------+------------+-----------------------|\n","| Train      | 0.212911 |     0.9394 |                  6.06 |\n","| Validation | 0.15574  |     0.9545 |                  4.55 |\n","| Test       | 0.247588 |     0.927  |                  7.3  |\n"]}],"source":["# evaluate performance\n","\n","print(\"Model performance :\")\n","headers = [\"\", \"Loss\", \"Accuracy\", \"Test error rate [%]\"]\n","\n","table = [ # 2nd column generates 2 column, the two output of the model (loss, and metric (accuracy)) / accuracy \n","    [\"Train\", *model.evaluate(x_train, y_train_onehot, verbose=0, batch_size=128), (1-model.evaluate(x_train, y_train_onehot, verbose=0, batch_size=128)[1])*100 ],\n","    [\"Validation\", *model.evaluate(x_valid, y_valid_onehot, verbose=0, batch_size=128), (1-model.evaluate(x_valid, y_valid_onehot, verbose=0, batch_size=128)[1])*100 ],\n","    [\"Test\", *model.evaluate(x_test, y_test_onehot, verbose=0, batch_size=128), (1-model.evaluate(x_test, y_test_onehot, verbose=0, batch_size=128)[1])*100 ],\n","]\n","\n","print(tabulate(table, headers=headers, tablefmt=\"orgtbl\"))"]},{"cell_type":"markdown","metadata":{"id":"rOUk5R71GRUo"},"source":["You can compare your own results with a variety of different models: http://yann.lecun.com/exdb/mnist/ and https://en.wikipedia.org/wiki/MNIST_database"]},{"cell_type":"markdown","metadata":{"id":"vj-JeG9_kIc-"},"source":["The following codeblocks define some helper functions for plotting. You don't need to touch them"]},{"cell_type":"code","execution_count":100,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1665174177638,"user":{"displayName":"Antoine Dupuis","userId":"12168416720763859895"},"user_tz":-120},"id":"kCxC5DPEkGLn"},"outputs":[],"source":["#@title \n","def plot_image(X, ax=None):                                                                                                                                    \n","    \"\"\"Plot an image X.                                                                                                                                        \n","                                                                                                                                                               \n","    Args:                                                                                                                                                      \n","        X (2D array): image, grayscale or RGB                                                                                                                  \n","        ax (None, optional): Description                                                                                                                       \n","    \"\"\"                                                                                                                                                        \n","    if ax is None:                                                                                                                                             \n","        ax = plt.gca()                                                                                                                                         \n","                                                                                                                                                               \n","    if (X.ndim == 2) or (X.shape[-1] == 1):                                                                                                                    \n","        ax.imshow(X.astype('uint8'), origin='upper', cmap=plt.cm.Greys)                                                                                        \n","    else:                                                                                                                                                      \n","        ax.imshow(X.astype('uint8'), origin='upper')                                                                                                           \n","                                                                                                                                                               \n","    ax.set(xticks=[], yticks=[]) \n","\n","def plot_prediction(Yp, X, y, classes=None, top_n=False):                                                                                          \n","    \"\"\"Plot an image along with all or the top_n predictions.                                                                                                  \n","                                                                                                                                                               \n","    Args:                                                                                                                                                      \n","        Yp (1D array): predicted probabilities for each class                                                                                                  \n","        X (2D array): image                                                                                                                                    \n","        y (integer): true class label                                                                                                                          \n","        classes (1D array, optional): class names                                                                                                              \n","        top_n (int, optional): number of top predictions to show\n","    \"\"\"                                                                                                                                                        \n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 3.2))                                                                                                     \n","    plt.subplots_adjust(left=0.02, right=0.98, bottom=0.15, top=0.98, wspace=0.02)                                                                             \n","    plot_image(X, ax1)                                                                                                                                         \n","                                                                                                                                                               \n","    if top_n:                                                                                                                                                  \n","        n = top_n                                                                                                                                              \n","        s = np.argsort(Yp)[-top_n:]                                                                                                                            \n","    else:                                                                                                                                                      \n","        n = len(Yp)                                                                                                                                            \n","        s = np.arange(n)[::-1]                                                                                                                                 \n","                                                                                                                                                               \n","    patches = ax2.barh(np.arange(n), Yp[s], align='center')                                                                                                    \n","    ax2.set(xlim=(0, 1), xlabel='Probability', yticks=[])                                                                                                      \n","                                                                                                                                                               \n","    for iy, patch in zip(s, patches):                                                                                                                          \n","        if iy == y:                                                                                                                                            \n","            patch.set_facecolor('C1')  # color correct patch                                                                                                   \n","                                                                                                                                                               \n","    if classes is None:                                                                                                                                        \n","        classes = np.arange(0, np.size(Yp))                                                                                                                    \n","                                                                                                                                                               \n","    for i in range(n):                                                                                                                                         \n","        ax2.text(0.05, i, classes[s][i], ha='left', va='center')                                                                                               \n","                                                                                                                                                               \n","    plt.show()\n","\n","def plot_confusion(yp, y, classes=None, fname=None):                                                                                                           \n","    \"\"\"Plot confusion matrix for given true and predicted class labels                                                                                         \n","                                                                                                                                                               \n","    Args:                                                                                                                                                      \n","        yp (1D array): predicted class labels                                                                                                                  \n","        y (1D array): true class labels                                                                                                                        \n","        classes (1D array): class names                                                                                                                        \n","        fname (str, optional): filename for saving the plot                                                                                                    \n","    \"\"\"                                                                                                                                                        \n","    if classes is None:                                                                                                                                        \n","        n = max(max(yp), max(y)) + 1                                                                                                                           \n","        classes = np.arange(n)                                                                                                                                 \n","    else:                                                                                                                                                      \n","        n = len(classes)                                                                                                                                       \n","                                                                                                                                                               \n","    bins = np.linspace(-0.5, n - 0.5, n + 1)                                                                                                                   \n","    C = np.histogram2d(y, yp, bins=bins)[0]                                                                                                                    \n","    C = C / np.sum(C, axis=0) * 100                                                                                                                            \n","                                                                                                                                                               \n","    fig = plt.figure(figsize=(8, 8))                                                                                                                           \n","    plt.imshow(C, interpolation='nearest', vmin=0, vmax=100, cmap=plt.cm.YlGnBu)                                                                               \n","    plt.gca().set_aspect('equal')                                                                                                                              \n","    cbar = plt.colorbar(shrink=0.8)                                                                                                                            \n","    cbar.set_label('Frequency %')                                                                                                                              \n","    plt.xlabel('Prediction')                                                                                                                                   \n","    plt.ylabel('Truth')                                                                                                                                        \n","    plt.xticks(range(n), classes, rotation='vertical')                                                                                                         \n","    plt.yticks(range(n), classes)                                                                                                                              \n","    for x in range(n):                                                                                                                                         \n","        for y in range(n):                                                                                                                                     \n","            if np.isnan(C[x, y]):                                                                                                                              \n","                continue                                                                                                                                       \n","            color = 'white' if x == y else 'black'                                                                                                             \n","            plt.annotate('%.1f' % (C[x, y]), xy=(y, x), color=color, ha='center', va='center')                                                                 \n","                                                                                                                                                               \n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZnfMRRv4kaKF"},"outputs":[],"source":["# plot a few examples, loop over test dataset:\n","# get missidentified samples\n","output = model.predict(x_test, batch_size=128)\n","labels = np.argmax(y_test_onehot, axis=1)\n","predictions = np.argmax(output, axis=1)\n","plot_confusion(predictions, labels)\n","\n","for i in range(10): # loop over first 10 test samples\n","    plot_prediction(output[i], \n","                    255 * np.reshape(x_test[i], (28, 28)), # we need to reshape the data into an image and convert back to RGB color scale by multiplying with 255\n","                    labels[i])\n","    "]},{"cell_type":"markdown","metadata":{"id":"fkluC7qesfJR"},"source":["Using the template (very nice), we plot the confusion matrix for the test dataset, as well as few example of good and wrong predictions with the image and the probability prediction associated."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YLaI35N6xUEe"},"outputs":[],"source":["# now plot a few examples that were misclassified\n","\n","indices_miss = np.nonzero(predictions != labels)[0]\n","x_missid = x_test[indices_miss]\n","\n","for i in indices_miss[:10]:\n","    plot_prediction(output[i], \n","                    255 * np.reshape(x_test[i], (28, 28)), # we need to reshape the data into an image and convert back to RGB color scale by multiplying with 255\n","                    labels[i])\n","\n","# or plot 32 of them in a joint plot\n","fig = plt.figure()\n","ax = fig.add_subplot(111)\n","plotdata = x_missid[:32]\n","plotdata = np.hstack(np.concatenate(np.reshape(plotdata, (4, 8, 28, 28)), axis=1))\n","ax.imshow(plotdata, cmap=\"gray\")\n"]},{"cell_type":"markdown","source":["# Experiment different network structure\n","\n","Number of trial have been done with three different umber of nodes (10, 50, 128)and layers (1, 10, 50). One can first observe that when the network get too deep (50 layers) the classification accuracy becomes irrelevant, that is around 0.1, giving strong insight on the negative effect of too deep network for this problem.\n","When it comes to the number of nodes, too little number impact negatively prediction accuracy (down to 0.91 for 10 neurons) whereas other values (128 and 50) seems close in terms of result ranging constantly around 0.97 in accuracy.\n","\n","For better configuration of the network, a grid search could be carried out."],"metadata":{"id":"uDPuvtIH2Ybh"}},{"cell_type":"markdown","metadata":{"id":"f4Ztv69IuffB"},"source":["**Grid search**\n","\n","Let's search the two hyperparameters dropout and number of nodes. You can start from the template below. \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V1uWtuoMvHqM"},"outputs":[],"source":["nb_layers = 1\n","batch_size_values = np.array([32, 64, 128])\n","n_neurons_values = np.array([50, 128, 300])\n","results_gridsearch = np.zeros((len(batch_size_values), len(n_neurons_values), 2))\n","for iDrop, drop in enumerate(batch_size_values):\n","  for iN, n_neurons in enumerate(n_neurons_values):\n","\n","    model = tf.keras.models.Sequential()\n","\n","    model.add(layers.Dense(n_neurons_values[iN], activation = 'ReLU', input_shape=(784,)))\n","    for i in range (1,nb_layers):\n","      model.add(layers.Dense(n_neurons_values[iN], activation = 'ReLU'))    \n","    model.add(layers.Dense(10, activation = 'softmax'))  # softmax actication to transform output into probabiliites\n","\n","    model.compile(\n","        loss='categorical_crossentropy',  # the recommended loss for a classification task is 'categorical_crossentropy' (see lecture for details)\n","        optimizer='adam',\n","        metrics=['accuracy']) # we use accuracy to quanitfy to network performance. \n","\n","    results = model.fit(\n","        x_train, y_train_onehot,\n","        validation_data=(x_valid, y_valid_onehot),\n","        batch_size=batch_size_values[iDrop],\n","        epochs=10,\n","        verbose=0\n","        )\n","    t = model.evaluate(x_test, y_test_onehot, verbose=0, batch_size=128)\n","    results_gridsearch[iDrop, iN] = t\n","    print(f\"batch size = {drop:.2f}, {n_neurons} neurons -> accuracy {results_gridsearch[iDrop, iN][1]:.3f}, error rate = {100*(1-results_gridsearch[iDrop, iN][1]):.1f}%\")\n"]},{"cell_type":"markdown","source":["After a grid search on two parameters, namely the batch size and the number of neurons, according to the result on the test dataset, the best highest accuracy was found to be equal to 0.980, which was found for:\n","batch size = 32, and 300 neurons !"],"metadata":{"id":"uBStD9VR7402"}},{"cell_type":"markdown","metadata":{"id":"OFxu8vLL00DM"},"source":["**Random seach**\n","\n","Now lets implement a random search. A random search allows us to scan more hyperparameters at once without more computing time. You can start from the template below. \n","\n","\n"]},{"cell_type":"code","execution_count":110,"metadata":{"id":"-Vg6oy8L06tP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665175097882,"user_tz":-120,"elapsed":610688,"user":{"displayName":"Antoine Dupuis","userId":"12168416720763859895"}},"outputId":"6de5c054-bd92-428e-fe50-9eec8459d6e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["iteration 0:\n","\tbatch_size: 64\n","\tnum_neurons: 128\n","\tlearn_rate: 0.001\n","\tactivation: relu\n","\tdropout: 0.5\n","\tval_acc: 0.9752500057220459\n","\t-> accuracy 0.975, error rate = 2.5%\n","iteration 1:\n","\tbatch_size: 16\n","\tnum_neurons: 512\n","\tlearn_rate: 0.0001\n","\tactivation: elu\n","\tdropout: 0.3\n","\tval_acc: 0.9642500281333923\n","\t-> accuracy 0.964, error rate = 3.6%\n","iteration 2:\n","\tbatch_size: 32\n","\tnum_neurons: 128\n","\tlearn_rate: 1.0\n","\tactivation: tanh\n","\tdropout: 0.1\n","\tval_acc: 0.6741250157356262\n","\t-> accuracy 0.674, error rate = 32.6%\n","iteration 3:\n","\tbatch_size: 16\n","\tnum_neurons: 512\n","\tlearn_rate: 0.0001\n","\tactivation: tanh\n","\tdropout: 0.3\n","\tval_acc: 0.9610000252723694\n","\t-> accuracy 0.961, error rate = 3.9%\n","iteration 4:\n","\tbatch_size: 256\n","\tnum_neurons: 8\n","\tlearn_rate: 0.001\n","\tactivation: sigmoid\n","\tdropout: 0.3\n","\tval_acc: 0.8709999918937683\n","\t-> accuracy 0.871, error rate = 12.9%\n","iteration 5:\n","\tbatch_size: 128\n","\tnum_neurons: 128\n","\tlearn_rate: 0.01\n","\tactivation: relu\n","\tdropout: 0.1\n","\tval_acc: 0.9668750166893005\n","\t-> accuracy 0.967, error rate = 3.3%\n","iteration 6:\n","\tbatch_size: 32\n","\tnum_neurons: 512\n","\tlearn_rate: 0.0001\n","\tactivation: elu\n","\tdropout: 0.1\n","\tval_acc: 0.9605000019073486\n","\t-> accuracy 0.961, error rate = 3.9%\n","iteration 7:\n","\tbatch_size: 128\n","\tnum_neurons: 256\n","\tlearn_rate: 0.0001\n","\tactivation: sigmoid\n","\tdropout: 0.0\n","\tval_acc: 0.9204999804496765\n","\t-> accuracy 0.920, error rate = 8.0%\n","iteration 8:\n","\tbatch_size: 64\n","\tnum_neurons: 8\n","\tlearn_rate: 0.01\n","\tactivation: sigmoid\n","\tdropout: 0.3\n","\tval_acc: 0.8790000081062317\n","\t-> accuracy 0.879, error rate = 12.1%\n","iteration 9:\n","\tbatch_size: 32\n","\tnum_neurons: 8\n","\tlearn_rate: 0.001\n","\tactivation: sigmoid\n","\tdropout: 0.5\n","\tval_acc: 0.8612499833106995\n","\t-> accuracy 0.861, error rate = 13.9%\n","iteration 10:\n","\tbatch_size: 32\n","\tnum_neurons: 128\n","\tlearn_rate: 0.1\n","\tactivation: sigmoid\n","\tdropout: 0.2\n","\tval_acc: 0.903124988079071\n","\t-> accuracy 0.903, error rate = 9.7%\n","iteration 11:\n","\tbatch_size: 256\n","\tnum_neurons: 512\n","\tlearn_rate: 1.0\n","\tactivation: elu\n","\tdropout: 0.2\n","\tval_acc: 0.7152500152587891\n","\t-> accuracy 0.715, error rate = 28.5%\n","iteration 12:\n","\tbatch_size: 64\n","\tnum_neurons: 128\n","\tlearn_rate: 0.0001\n","\tactivation: tanh\n","\tdropout: 0.2\n","\tval_acc: 0.9396250247955322\n","\t-> accuracy 0.940, error rate = 6.0%\n","iteration 13:\n","\tbatch_size: 64\n","\tnum_neurons: 128\n","\tlearn_rate: 0.01\n","\tactivation: elu\n","\tdropout: 0.3\n","\tval_acc: 0.9637500047683716\n","\t-> accuracy 0.964, error rate = 3.6%\n","iteration 14:\n","\tbatch_size: 256\n","\tnum_neurons: 8\n","\tlearn_rate: 0.0001\n","\tactivation: sigmoid\n","\tdropout: 0.6\n","\tval_acc: 0.6917499899864197\n","\t-> accuracy 0.692, error rate = 30.8%\n","iteration 15:\n","\tbatch_size: 64\n","\tnum_neurons: 32\n","\tlearn_rate: 0.01\n","\tactivation: tanh\n","\tdropout: 0.2\n","\tval_acc: 0.9477499723434448\n","\t-> accuracy 0.948, error rate = 5.2%\n","iteration 16:\n","\tbatch_size: 64\n","\tnum_neurons: 32\n","\tlearn_rate: 1.0\n","\tactivation: sigmoid\n","\tdropout: 0.6\n","\tval_acc: 0.23325000703334808\n","\t-> accuracy 0.233, error rate = 76.7%\n","iteration 17:\n","\tbatch_size: 256\n","\tnum_neurons: 8\n","\tlearn_rate: 0.0001\n","\tactivation: sigmoid\n","\tdropout: 0.1\n","\tval_acc: 0.7440000176429749\n","\t-> accuracy 0.744, error rate = 25.6%\n","iteration 18:\n","\tbatch_size: 64\n","\tnum_neurons: 128\n","\tlearn_rate: 0.01\n","\tactivation: relu\n","\tdropout: 0.5\n","\tval_acc: 0.9602500200271606\n","\t-> accuracy 0.960, error rate = 4.0%\n","iteration 19:\n","\tbatch_size: 128\n","\tnum_neurons: 8\n","\tlearn_rate: 0.1\n","\tactivation: tanh\n","\tdropout: 0.0\n","\tval_acc: 0.8715000152587891\n","\t-> accuracy 0.872, error rate = 12.8%\n"]}],"source":["N = 20 # number of trials \n","search = {\n","'batch_size': np.random.choice([16, 32, 64, 128, 256], N),\n","'num_neurons': np.random.choice([8, 32, 128, 256, 512], N),\n","'learn_rate': np.random.choice([0.0001, 0.001, 0.01, 0.1, 1],N),\n","'activation': np.random.choice(['relu', 'elu', 'sigmoid', 'tanh'], N),\n","'dropout': np.random.choice([0.0, 0.1, 0.2, 0.3, 0.5, 0.6], N),\n","'val_acc': np.zeros(N)\n","}\n","\n","for i in range(N):\n","  # you can access the current value of the hyperparameter with `search['batch_size'][i]`\n","  model = tf.keras.models.Sequential([\n","                      tf.keras.layers.Dense(search['num_neurons'][i], activation = search['activation'][i], input_shape=(784,)),\n","                      #tf.keras.layers.Dropout(search['dropout'][i]),#, activation = search['activation'][i], input_shape=(784,)),\n","                      tf.keras.layers.Dropout(search['dropout'][i]),\n","                      tf.keras.layers.Dense(10, activation='softmax')])\n","  \n","  optimizer = tf.keras.optimizers.Adam(learning_rate=search['learn_rate'][i])\n","  model.compile(loss='categorical_crossentropy',\n","  optimizer=optimizer,\n","  metrics=['accuracy'])\n","\n","  #print(model.summary())\n","\n","  results = model.fit(\n","        x_train, y_train_onehot,\n","        validation_data=(x_valid, y_valid_onehot),\n","        batch_size=search['batch_size'][i],\n","        epochs=10,\n","        verbose=0\n","      )\n","  \n","  \n","  \n","  search['val_acc'][i] = model.evaluate(x_test, y_test_onehot, verbose=0, batch_size=128)[1]\n","  print(f\"iteration {i}:\")\n","  for key in search:\n","    print(f\"\\t{key}: {search[key][i]}\")\n","  print(f\"\\t-> accuracy {search['val_acc'][i]:.3f}, error rate = {100*(1-search['val_acc'][i]):.1f}%\")\n"]},{"cell_type":"markdown","source":["After a random search on 5 parameters, with 20 trials, the best highest accuracy was found to be equal to 0.975, which was found for: \n","batch size = 64, 128 neurons, learning rate = 0.001, dropout = 0.5 and relu activation function !\n","\n","One can observe that the best model found with random search has an accuracy very close to the one found with grid search, but slightly worse (0.975 < 0.980)!"],"metadata":{"id":"JKLSQmtiI1ik"}}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[{"file_id":"1_R1oOLTtHlpSGlusWjNgw0za0mbn-trt","timestamp":1665137501600}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}